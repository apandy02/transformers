{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7GuoX-D2SUi"
      },
      "source": [
        "# Decoder-only based GPT (language model)\n",
        "\n",
        "Here we take a transformer block, the decoder in particular, and use it for the task of language modeling. In general, this is how GPTs are trained. We will do this on a much smaller scale.\n",
        "\n",
        "We take everything we've already built and leverage it in the way Karpathy implements a character level LM here:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ptBhD9c3kTU",
        "outputId": "3f3e415e-0701-410b-b055-6d5aa14d090d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp drive/MyDrive/Transformers/models/transformer_blocks.py .\n",
        "!cp drive/MyDrive/Transformers/models/modules.py .\n",
        "!cp -r drive/MyDrive/Transformers/data/ ."
      ],
      "metadata": {
        "id": "DAnCCtxa3i6o"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenmonster"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_XqFHTe4Ozn",
        "outputId": "805b6cfb-4910-4fb6-c30b-15a4a9b32767"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tokenmonster in /usr/local/lib/python3.10/dist-packages (1.1.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "p0LzXILI2SUk"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import numpy as np\n",
        "from torch.utils.data import random_split\n",
        "import sys\n",
        "sys.path.append(\"~/\")\n",
        "from transformer_blocks import Transformer\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tokenmonster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "UP_BMiE52SUl",
        "outputId": "b52733bb-47e8-47a5-a6e9-1dbeab757be3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2652650\n"
          ]
        }
      ],
      "source": [
        "harry_potter_text = \" \"\n",
        "for i in range(4):\n",
        "    book_num = i+1\n",
        "    with open(f'/content/data/hp{book_num}.txt', 'r', encoding='utf-8') as f:\n",
        "        harry_potter_text += f.read()\n",
        "print(len(harry_potter_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTW6wJWB2SUl"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WTsFKtP2SUm"
      },
      "source": [
        "## Tokenization\n",
        "Instead of character level, we're going to model this LM using a tokenizer. in particular, we're going to try to use OpenAI's tiktoken with the gpt2 50k tokenizer. This might end up being too large of a vocab size given compute constraints, but"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "jNAlYTIf2SUm"
      },
      "outputs": [],
      "source": [
        "vocab = tokenmonster.load(\"fiction-2048-consistent-v1\")\n",
        "tokens = vocab.tokenize(\"This is a test.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "ya_OlheL2SUm",
        "outputId": "ccb1a3bb-ada7-430a-b770-24bc930597c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([138, 918, 108, 318, 202,  17], dtype=uint16)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "nZ0pfOIT2SUm"
      },
      "outputs": [],
      "source": [
        "token_example = vocab.tokenize(\"hello world test monster tokenizer\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "y1y5eYUD2SUn",
        "outputId": "715a0885-76d6-45c7-a054-42032d9d6957",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 37, 445, 174, 785, 318, 202, 465, 547, 321, 169, 181, 218,  62],\n",
              "      dtype=uint16)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "token_example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "-qyadxmt2SUn",
        "outputId": "e2971523-4e0a-41f2-de28-5d0838c578dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['',\n",
              " ' hel',\n",
              " 'lo',\n",
              " ' world',\n",
              " ' te',\n",
              " 'st',\n",
              " ' mon',\n",
              " 'ster',\n",
              " ' to',\n",
              " 'ke',\n",
              " 'ni',\n",
              " 'ze',\n",
              " 'r']"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "[vocab.decode([token]) for token in token_example]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "2ks4lD6p2SUn"
      },
      "outputs": [],
      "source": [
        "tokens = np.array(vocab.tokenize(harry_potter_text), dtype=np.float16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "WH_4N1qN2SUn",
        "outputId": "0eb61ddd-81d9-4ce2-9fed-c01b649eb98f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1050223]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "dataset = torch.tensor(tokens, dtype=torch.long)\n",
        "print(dataset.shape, dataset.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "rOqbUh7U2SUn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf05915e-373c-40a6-f9c2-304a412a7292"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Harry Potter and the Sorcerer's Stone\n",
            "\n",
            "\n",
            "CHAPTER ONE\n",
            "\n",
            "THE BOY WHO LIVED\n",
            "\n",
            "Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say\n",
            "that they were perfectly normal, thank you very much. They were the last\n",
            "people you'd expect to be\n",
            "rry muttered.  \"Listen, you'd better go and get someone -\"\n",
            "\"Dumbledore!\" gasped Mr. Crouch. He reached out and seized a handful of Harrys robes, dragging him closer, though his eyes were staring over Harry's head.  \"I need... see\n",
            " Harry.\n",
            "\"Would Harry Potter like a cup of tea?\" he squeaked loudly, over Winky's sobs.\n",
            "\"Er - yeah, okay,\" said Harry.\n",
            "Instantly, about six house-elves came trotting up behind him, bearing a large silver tray laden with a te\n"
          ]
        }
      ],
      "source": [
        "train_size = int(len(dataset) * 0.8)\n",
        "test_size = int(len(dataset) * 0.1)\n",
        "val_size = len(dataset) - train_size - test_size\n",
        "\n",
        "train_data, test_data, val_data = dataset[:train_size], dataset[train_size:train_size+test_size], dataset[train_size+test_size:]\n",
        "\n",
        "train_block = torch.tensor([train_data[i] for i in range(100)])\n",
        "train_list = train_block.tolist()\n",
        "print(vocab.decode(train_list))\n",
        "\n",
        "val_block = torch.tensor([val_data[i] for i in range(100)])\n",
        "val_list = val_block.tolist()\n",
        "print(vocab.decode(val_list))\n",
        "\n",
        "test_block = torch.tensor([test_data[i] for i in range(100)])\n",
        "test_list = test_block.tolist()\n",
        "print(vocab.decode(test_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "VoWJLYvs2SUo",
        "outputId": "0a99fd63-5417-4cf2-da31-2b2d9141a1ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set size: 840178, test: 105022, val: 105023\n"
          ]
        }
      ],
      "source": [
        "print(f\"train set size: {train_size}, test: {test_size}, val: {val_size}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "RbbeNPTF2SUo"
      },
      "outputs": [],
      "source": [
        "class HPDataset(Dataset):\n",
        "    def __init__(self, data, block_size):\n",
        "        self.data = data\n",
        "        self.block_size = block_size\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the total number of possible sequences\n",
        "        return len(self.data) - self.block_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Fetch a single sequence x and its corresponding target y\n",
        "        x = self.data[idx:idx + self.block_size]\n",
        "        y = self.data[idx + 1:idx + self.block_size + 1]\n",
        "        return x, y\n",
        "\n",
        "BLOCK_SIZE = 8\n",
        "train_dataset, val_dataset, test_dataset = HPDataset(train_data, BLOCK_SIZE), HPDataset(val_data, BLOCK_SIZE), HPDataset(test_data, BLOCK_SIZE)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader, val_loader, test_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True), DataLoader(val_dataset, batch_size=batch_size, shuffle=True), DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "H9AWjLIa2SUo",
        "outputId": "fb071a73-a88f-4470-dd37-79cef8119ce5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17504\n",
            "2188\n",
            "2188\n"
          ]
        }
      ],
      "source": [
        "print(len(train_loader))\n",
        "print(len(test_loader))\n",
        "print(len(val_loader))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "9D0dkIBU2SUo"
      },
      "outputs": [],
      "source": [
        "class zeptoGPT(nn.Module):\n",
        "    \"\"\"\n",
        "    zepto because it's a really small GPT\n",
        "    \"\"\"\n",
        "    def __init__(self, d_k, d_model, d_v, d_ff, num_heads, num_layers, vocab_size, dropout=0.1) -> None:\n",
        "        super().__init__()\n",
        "        self.decoder_transformer = Transformer(d_k, d_model, d_v, d_ff, num_heads, num_layers, vocab_size=vocab_size, mask=True, dropout=dropout)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.layer_norm = nn.LayerNorm(d_model)\n",
        "        self.fc = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.decoder_transformer(x)\n",
        "        return self.fc(self.layer_norm(out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "oHC-Secr2SUo"
      },
      "outputs": [],
      "source": [
        "def compute_loss(y_target, y_pred, loss_function):\n",
        "    B, T, C = y_pred.shape\n",
        "    y_pred = y_pred.view(B*T, C)\n",
        "    _, max_indices = torch.max(y_pred, dim=1)\n",
        "    y_target_list = y_target.tolist()\n",
        "    max_indices = max_indices.tolist()\n",
        "    y_target = y_target.view(B*T)\n",
        "    return loss_function(y_pred, y_target)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(model, prompt: str, device,n = 50, block_size=BLOCK_SIZE):\n",
        "  prompt_array = vocab.tokenize(prompt)\n",
        "  print(prompt_array.shape)\n",
        "  prompt_array = np.array(prompt_array[:block_size], dtype=np.int16)\n",
        "  print(prompt_array.shape)\n",
        "  print(prompt_array.tolist())\n",
        "  decoded = vocab.decode(prompt_array)\n",
        "  print(f\"prompt: {decoded}\")\n",
        "  cumulative_array = prompt_array\n",
        "  for i in range(n):\n",
        "    prompt_tensor = torch.tensor(prompt_array, dtype=torch.long).to(device)\n",
        "    next_token = predict_next_token(model, prompt_tensor.unsqueeze(0))\n",
        "    next_token_np = next_token.cpu().numpy().flatten()\n",
        "    cumulative_array = np.append(cumulative_array, next_token_np)\n",
        "    prompt_array = np.append(prompt_array[1:], next_token_np)\n",
        "    test_list = cumulative_array.tolist()\n",
        "    print(vocab.decode(test_list))"
      ],
      "metadata": {
        "id": "5Pc9PN-Hnrv-"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_next_token(model, block):\n",
        "  with torch.no_grad():\n",
        "    y_pred = model(block)\n",
        "    token_probs = nn.functional.softmax(y_pred, dim=-1)\n",
        "    _, max_idx = torch.max(token_probs, dim=-1)\n",
        "  return max_idx.squeeze()[-1]  # return only the last next token prediction"
      ],
      "metadata": {
        "id": "XQ7fkR1zJlI4"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "W2wS6j8Y2SUo"
      },
      "outputs": [],
      "source": [
        "def train(model, train_loader, val_loader, loss_function, optim, epochs, device):\n",
        "    losses = [] #group losses for loss visualization\n",
        "    running_loss = 0.0\n",
        "    val_losses = []\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        print(\"Epoch %d / %d\" % (epoch+1, epochs))\n",
        "        print(\"-\"*10)\n",
        "\n",
        "        for i, batch_data in enumerate(train_loader):\n",
        "            x, y = batch_data\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            y_pred = model(x)\n",
        "\n",
        "            loss = compute_loss(y, y_pred, loss_function)\n",
        "            optim.zero_grad()\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            running_loss += loss.item()\n",
        "            losses.append(loss)\n",
        "\n",
        "            if (i+1) % 1000 == 0:\n",
        "                print(\"Step: {}, average training loss over last 1000 steps: {:.4f}\".format(i+1, running_loss/1000))\n",
        "                running_loss = 0.0\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            correct_pred = 0.0\n",
        "            num_samples = 0\n",
        "            for i, batch_data in enumerate(val_loader):\n",
        "                (y, x) = batch_data\n",
        "                y, x = y.to(device), x.to(device)\n",
        "                y_pred = model(x)\n",
        "                loss = compute_loss(y, y_pred, loss_function)\n",
        "                _, predicted_labels = torch.max(y_pred, 1)\n",
        "                num_samples+=predicted_labels.shape[0]\n",
        "                val_loss += loss.item()\n",
        "\n",
        "            val_losses.append(val_loss)\n",
        "        print(\"Epoch: {}, validation loss: {:.4f}\".format(epoch+1, val_loss/len(val_loader)))\n",
        "        print(\"Generated text: \")\n",
        "        generate(model, \"Harry\", device=DEVICE, n=20)\n",
        "\n",
        "    return losses, val_losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "yj_S3bSm2SUo"
      },
      "outputs": [],
      "source": [
        "LEARNING_RATE = 6e-4\n",
        "NUM_EPOCHS = 5\n",
        "DROPOUT = 0.2\n",
        "D_MODEL = 1024\n",
        "NUM_HEADS = 8\n",
        "D_K = int(D_MODEL / NUM_HEADS)\n",
        "D_V = D_K\n",
        "D_FF = D_MODEL * 4\n",
        "NUM_LAYERS = 1\n",
        "VOCAB_SIZE = vocab.vocab_size\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "f314V3J12SUo"
      },
      "outputs": [],
      "source": [
        "model = zeptoGPT(D_K, D_MODEL, D_V, D_FF, num_heads=NUM_HEADS, num_layers=NUM_LAYERS, vocab_size=VOCAB_SIZE)\n",
        "model = model.to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "iqdfCB9C2SUo"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DEVICE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bWmZ65uO6XhP",
        "outputId": "21bbe9ca-82ff-4302-fd5b-e350aaf31b10"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "RxStEdDG2SUp",
        "outputId": "8dd20cc6-7ab6-4b4d-c1ae-e74773fe686e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 5\n",
            "----------\n",
            "Step: 1000, average training loss over last 1000 steps: 4.3394\n",
            "Step: 2000, average training loss over last 1000 steps: 3.9748\n",
            "Step: 3000, average training loss over last 1000 steps: 3.8851\n",
            "Step: 4000, average training loss over last 1000 steps: 3.8332\n",
            "Step: 5000, average training loss over last 1000 steps: 3.7971\n",
            "Step: 6000, average training loss over last 1000 steps: 3.7624\n",
            "Step: 7000, average training loss over last 1000 steps: 3.7365\n",
            "Step: 8000, average training loss over last 1000 steps: 3.7158\n",
            "Step: 9000, average training loss over last 1000 steps: 3.6864\n",
            "Step: 10000, average training loss over last 1000 steps: 3.6808\n",
            "Step: 11000, average training loss over last 1000 steps: 3.6572\n",
            "Step: 12000, average training loss over last 1000 steps: 3.6393\n",
            "Step: 13000, average training loss over last 1000 steps: 3.6187\n",
            "Step: 14000, average training loss over last 1000 steps: 3.6135\n",
            "Step: 15000, average training loss over last 1000 steps: 3.5964\n",
            "Step: 16000, average training loss over last 1000 steps: 3.5884\n",
            "Step: 17000, average training loss over last 1000 steps: 3.5813\n",
            "Epoch: 1, validation loss: 8.5911\n",
            "Generated text: \n",
            "(4,)\n",
            "(4,)\n",
            "[138, 264, 62, 196]\n",
            "prompt: Harry\n",
            "Harry,\n",
            "Harry, and\n",
            "Harry, and\n",
            "Harry, and Ro\n",
            "Harry, and Ron\n",
            "Harry, and Ron,\n",
            "Harry, and Ron, and\n",
            "Harry, and Ron, and\n",
            "Harry, and Ron, and Her\n",
            "Harry, and Ron, and Her\n",
            "Harry, and Ron, and Hermi\n",
            "Harry, and Ron, and Hermione\n",
            "Harry, and Ron, and Hermione,\n",
            "Harry, and Ron, and Hermione, and\n",
            "Harry, and Ron, and Hermione, and\n",
            "Harry, and Ron, and Hermione, and Ha\n",
            "Harry, and Ron, and Hermione, and Har\n",
            "Harry, and Ron, and Hermione, and Harry\n",
            "Harry, and Ron, and Hermione, and Harry,\n",
            "Harry, and Ron, and Hermione, and Harry, and\n",
            "Epoch 2 / 5\n",
            "----------\n",
            "Step: 1000, average training loss over last 1000 steps: 5.3588\n",
            "Step: 2000, average training loss over last 1000 steps: 3.5465\n",
            "Step: 3000, average training loss over last 1000 steps: 3.5402\n",
            "Step: 4000, average training loss over last 1000 steps: 3.5329\n",
            "Step: 5000, average training loss over last 1000 steps: 3.5305\n",
            "Step: 6000, average training loss over last 1000 steps: 3.5202\n",
            "Step: 7000, average training loss over last 1000 steps: 3.5135\n",
            "Step: 8000, average training loss over last 1000 steps: 3.5032\n",
            "Step: 9000, average training loss over last 1000 steps: 3.5053\n",
            "Step: 10000, average training loss over last 1000 steps: 3.4905\n",
            "Step: 11000, average training loss over last 1000 steps: 3.4881\n",
            "Step: 12000, average training loss over last 1000 steps: 3.4812\n",
            "Step: 13000, average training loss over last 1000 steps: 3.4725\n",
            "Step: 14000, average training loss over last 1000 steps: 3.4670\n",
            "Step: 15000, average training loss over last 1000 steps: 3.4599\n",
            "Step: 16000, average training loss over last 1000 steps: 3.4554\n",
            "Step: 17000, average training loss over last 1000 steps: 3.4540\n",
            "Epoch: 2, validation loss: 8.8139\n",
            "Generated text: \n",
            "(4,)\n",
            "(4,)\n",
            "[138, 264, 62, 196]\n",
            "prompt: Harry\n",
            "Harry's\n",
            "Harry's face\n",
            "Harry's face,\n",
            "Harry's face, and\n",
            "Harry's face, and\n",
            "Harry's face, and Ha\n",
            "Harry's face, and Har\n",
            "Harry's face, and Harry\n",
            "Harry's face, and Harry's\n",
            "Harry's face, and Harry's\n",
            "\n",
            "Harry's face, and Harry's\n",
            "the\n",
            "Harry's face, and Harry's\n",
            "they\n",
            "Harry's face, and Harry's\n",
            "they'\n",
            "Harry's face, and Harry's\n",
            "they're\n",
            "Harry's face, and Harry's\n",
            "they're not\n",
            "Harry's face, and Harry's\n",
            "they're not to\n",
            "Harry's face, and Harry's\n",
            "they're not to\n",
            "Harry's face, and Harry's\n",
            "they're not to Ha\n",
            "Harry's face, and Harry's\n",
            "they're not to Har\n",
            "Harry's face, and Harry's\n",
            "they're not to Harry\n",
            "Epoch 3 / 5\n",
            "----------\n",
            "Step: 1000, average training loss over last 1000 steps: 5.1701\n",
            "Step: 2000, average training loss over last 1000 steps: 3.4273\n",
            "Step: 3000, average training loss over last 1000 steps: 3.4341\n",
            "Step: 4000, average training loss over last 1000 steps: 3.4176\n",
            "Step: 5000, average training loss over last 1000 steps: 3.4285\n",
            "Step: 6000, average training loss over last 1000 steps: 3.4139\n",
            "Step: 7000, average training loss over last 1000 steps: 3.4149\n",
            "Step: 8000, average training loss over last 1000 steps: 3.4132\n",
            "Step: 9000, average training loss over last 1000 steps: 3.4082\n",
            "Step: 10000, average training loss over last 1000 steps: 3.3986\n",
            "Step: 11000, average training loss over last 1000 steps: 3.4033\n",
            "Step: 12000, average training loss over last 1000 steps: 3.3962\n",
            "Step: 13000, average training loss over last 1000 steps: 3.3903\n",
            "Step: 14000, average training loss over last 1000 steps: 3.3898\n",
            "Step: 15000, average training loss over last 1000 steps: 3.3784\n",
            "Step: 16000, average training loss over last 1000 steps: 3.3790\n",
            "Step: 17000, average training loss over last 1000 steps: 3.3789\n",
            "Epoch: 3, validation loss: 8.9292\n",
            "Generated text: \n",
            "(4,)\n",
            "(4,)\n",
            "[138, 264, 62, 196]\n",
            "prompt: Harry\n",
            "Harry's\n",
            "Harry's\n",
            "\n",
            "Harry's\n",
            "the\n",
            "Harry's\n",
            "they\n",
            "Harry's\n",
            "they'\n",
            "Harry's\n",
            "they'd\n",
            "Harry's\n",
            "they'd be\n",
            "Harry's\n",
            "they'd be \n",
            "Harry's\n",
            "they'd be able\n",
            "Harry's\n",
            "they'd be able to\n",
            "Harry's\n",
            "they'd be able to\n",
            "Harry's\n",
            "they'd be able to Ha\n",
            "Harry's\n",
            "they'd be able to Har\n",
            "Harry's\n",
            "they'd be able to Harry\n",
            "Harry's\n",
            "they'd be able to Harry's\n",
            "Harry's\n",
            "they'd be able to Harry's\n",
            "\n",
            "Harry's\n",
            "they'd be able to Harry's\n",
            "the\n",
            "Harry's\n",
            "they'd be able to Harry's\n",
            "they\n",
            "Harry's\n",
            "they'd be able to Harry's\n",
            "they'\n",
            "Harry's\n",
            "they'd be able to Harry's\n",
            "they'd\n",
            "Epoch 4 / 5\n",
            "----------\n",
            "Step: 1000, average training loss over last 1000 steps: 5.0545\n",
            "Step: 2000, average training loss over last 1000 steps: 3.3623\n",
            "Step: 3000, average training loss over last 1000 steps: 3.3592\n",
            "Step: 4000, average training loss over last 1000 steps: 3.3540\n",
            "Step: 5000, average training loss over last 1000 steps: 3.3509\n",
            "Step: 6000, average training loss over last 1000 steps: 3.3463\n",
            "Step: 7000, average training loss over last 1000 steps: 3.3414\n",
            "Step: 8000, average training loss over last 1000 steps: 3.3476\n",
            "Step: 9000, average training loss over last 1000 steps: 3.3460\n",
            "Step: 10000, average training loss over last 1000 steps: 3.3459\n",
            "Step: 11000, average training loss over last 1000 steps: 3.3359\n",
            "Step: 12000, average training loss over last 1000 steps: 3.3315\n",
            "Step: 13000, average training loss over last 1000 steps: 3.3265\n",
            "Step: 14000, average training loss over last 1000 steps: 3.3276\n",
            "Step: 15000, average training loss over last 1000 steps: 3.3210\n",
            "Step: 16000, average training loss over last 1000 steps: 3.3205\n",
            "Step: 17000, average training loss over last 1000 steps: 3.3222\n",
            "Epoch: 4, validation loss: 9.0454\n",
            "Generated text: \n",
            "(4,)\n",
            "(4,)\n",
            "[138, 264, 62, 196]\n",
            "prompt: Harry\n",
            "Harry's\n",
            "Harry's face\n",
            "Harry's face was\n",
            "Harry's face was\n",
            "\n",
            "Harry's face was\n",
            "and\n",
            "Harry's face was\n",
            "and\n",
            "Harry's face was\n",
            "and Ro\n",
            "Harry's face was\n",
            "and Ron\n",
            "Harry's face was\n",
            "and Ron,\n",
            "Harry's face was\n",
            "and Ron, and\n",
            "Harry's face was\n",
            "and Ron, and\n",
            "Harry's face was\n",
            "and Ron, and Her\n",
            "Harry's face was\n",
            "and Ron, and Her\n",
            "Harry's face was\n",
            "and Ron, and Hermi\n",
            "Harry's face was\n",
            "and Ron, and Hermione\n",
            "Harry's face was\n",
            "and Ron, and Hermione,\n",
            "Harry's face was\n",
            "and Ron, and Hermione, and\n",
            "Harry's face was\n",
            "and Ron, and Hermione, and\n",
            "Harry's face was\n",
            "and Ron, and Hermione, and Her\n",
            "Harry's face was\n",
            "and Ron, and Hermione, and Her\n",
            "Epoch 5 / 5\n",
            "----------\n",
            "Step: 1000, average training loss over last 1000 steps: 4.9746\n",
            "Step: 2000, average training loss over last 1000 steps: 3.3053\n",
            "Step: 3000, average training loss over last 1000 steps: 3.2999\n",
            "Step: 4000, average training loss over last 1000 steps: 3.2955\n",
            "Step: 5000, average training loss over last 1000 steps: 3.3031\n",
            "Step: 6000, average training loss over last 1000 steps: 3.2967\n",
            "Step: 7000, average training loss over last 1000 steps: 3.2928\n",
            "Step: 8000, average training loss over last 1000 steps: 3.2905\n",
            "Step: 9000, average training loss over last 1000 steps: 3.2892\n",
            "Step: 10000, average training loss over last 1000 steps: 3.2880\n",
            "Step: 11000, average training loss over last 1000 steps: 3.2856\n",
            "Step: 12000, average training loss over last 1000 steps: 3.2953\n",
            "Step: 13000, average training loss over last 1000 steps: 3.2789\n",
            "Step: 14000, average training loss over last 1000 steps: 3.2828\n",
            "Step: 15000, average training loss over last 1000 steps: 3.2779\n",
            "Step: 16000, average training loss over last 1000 steps: 3.2714\n",
            "Step: 17000, average training loss over last 1000 steps: 3.2802\n",
            "Epoch: 5, validation loss: 9.1529\n",
            "Generated text: \n",
            "(4,)\n",
            "(4,)\n",
            "[138, 264, 62, 196]\n",
            "prompt: Harry\n",
            "Harry,\n",
            "Harry, and\n",
            "Harry, and\n",
            "Harry, and Ro\n",
            "Harry, and Ron\n",
            "Harry, and Ron,\n",
            "Harry, and Ron, and\n",
            "Harry, and Ron, and\n",
            "Harry, and Ron, and Her\n",
            "Harry, and Ron, and Her\n",
            "Harry, and Ron, and Hermi\n",
            "Harry, and Ron, and Hermione\n",
            "Harry, and Ron, and Hermione,\n",
            "Harry, and Ron, and Hermione, however,\n",
            "Harry, and Ron, and Hermione, however, was\n",
            "Harry, and Ron, and Hermione, however, was\n",
            "\n",
            "Harry, and Ron, and Hermione, however, was\n",
            "the\n",
            "Harry, and Ron, and Hermione, however, was\n",
            "they\n",
            "Harry, and Ron, and Hermione, however, was\n",
            "they\n",
            "Harry, and Ron, and Hermione, however, was\n",
            "theymi\n"
          ]
        }
      ],
      "source": [
        "train_loss, val_loss = train(model, train_loader, val_loader, torch.nn.functional.cross_entropy, optimizer, NUM_EPOCHS, DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_sample = train_data"
      ],
      "metadata": {
        "id": "3m2I7HS8MO8M"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_sample[0])\n",
        "test_block = torch.tensor([text_sample[i] for i in range(8)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXfqcgw2MYSz",
        "outputId": "425d9c94-ece0-41b0-b071-433c546e5aa5"
      },
      "execution_count": 104,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(36)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_block"
      ],
      "metadata": {
        "id": "nJXjZzCnMoSY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a3e9f2b-f029-4f3f-9c7b-77ea29b7cd24"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 36, 264,  62, 196,  36, 301,  64, 382])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_list = test_block.tolist()"
      ],
      "metadata": {
        "id": "m0uewcO7MwY_"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.decode(test_list)"
      ],
      "metadata": {
        "id": "P8mbTFkAMpic",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ed44a0c9-1449-4aa5-c4f0-04c03eebb080"
      },
      "execution_count": 107,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' Harry Potter'"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_block = torch.tensor([text_sample[i] for i in range(100)])\n",
        "test_list = test_block.tolist()\n",
        "vocab.decode(test_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "aAN0uzbYhKa8",
        "outputId": "04ce2be6-d849-4a5c-c81a-920c4b181cc5"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" Harry Potter and the Sorcerer's Stone\\n\\n\\nCHAPTER ONE\\n\\nTHE BOY WHO LIVED\\n\\nMr. and Mrs. Dursley, of number four, Privet Drive, were proud to say\\nthat they were perfectly normal, thank you very much. They were the last\\npeople you'd expect to be\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate(model, \"in the dark\", device= DEVICE, n = 25)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XrBrg4lRhOuv",
        "outputId": "c370a1ee-cda6-4983-f071-58fa9527e1a5"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3,)\n",
            "(3,)\n",
            "[37, 827, 570]\n",
            "prompt: in the dark\n",
            "in the darkness\n",
            "in the darkness,\n",
            "in the darkness, and\n",
            "in the darkness, and\n",
            "in the darkness, and Ha\n",
            "in the darkness, and Har\n",
            "in the darkness, and Harry\n",
            "in the darkness, and Harry had\n",
            "in the darkness, and Harry had seen\n",
            "in the darkness, and Harry had seen before\n",
            "in the darkness, and Harry had seen before the\n",
            "in the darkness, and Harry had seen before the\n",
            "in the darkness, and Harry had seen before the Mi\n",
            "in the darkness, and Harry had seen before the Mini\n",
            "in the darkness, and Harry had seen before the Minist\n",
            "in the darkness, and Harry had seen before the Ministry\n",
            "in the darkness, and Harry had seen before the Ministry of\n",
            "in the darkness, and Harry had seen before the Ministry of\n",
            "in the darkness, and Harry had seen before the Ministry of Ma\n",
            "in the darkness, and Harry had seen before the Ministry of Mag\n",
            "in the darkness, and Harry had seen before the Ministry of Magic\n",
            "in the darkness, and Harry had seen before the Ministry of Magic,\n",
            "in the darkness, and Harry had seen before the Ministry of Magic, and\n",
            "in the darkness, and Harry had seen before the Ministry of Magic, and\n",
            "in the darkness, and Harry had seen before the Ministry of Magic, and Ha\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}